\section{\uppercase{Empirical Study}}
\label{sec:exp}
The pattern is implemented in Papyrus Designer \cite{PapyrusDesigner}, which is an extension of the UML modeling tool Papyrus \cite{cealistpapyrus}.
Papyrus Designer supports component-based modeling and code generation. 
The behavior of a component in Papyrus Designer is described by using UML State Machines.
The tool allows to use some time notions from the MARTE profile to specify time events.
C++ code is generated and runs within POSIX systems such as Ubuntu, in which Pthreads are used for implementing threads for concurrency. 
This section reports our experiments with Papyrus Designer on the semantic-conformance and efficiency of generated code.

\subsection{Semantic conformance of runtime execution}
\label{subsec:exp1}
This section presents our results found during experiments with our tool to answer the following research question.

\noindent
	\begin{mdframed}[backgroundcolor=blue!5]
		\small
		\tb{\ti{Research question 1:}} \ti{Is the runtime execution of code generated from USMs by our tool semantic-conformant to PSSM?}
	\end{mdframed}


To evaluate the semantic conformance of runtime execution of generated code, we use a set of examples provided by Moka \cite{moka}, which is a model execution engine offering PSSM (and also part of the Papyrus modeler). 
Fig. \ref{fig:semanticconformance} shows our method. 
%We first use our code generator to generate code (Step (1)) from the Moka example model set. 
%Step (2) simulates the examples by using Moka to extract the sequence (\tb{Traces 1}) of observed traces including executed actions. 
%The sequence (\tb{Traces 2}) is also obtained through the runtime execution of the code generated in Step (1). 
%The code is semantic-conformant if \tb{Traces 1} and \tb{Traces 2} are the same \cite{Blech2005}. %The current version of Moka does not support simulation for \ti{TimeEvent} and history pseudo states, we therefore leave experiments for \ti{TimeEvent} as future work.
The latter consists of the following steps:

\begin{description}
	\item[Step 1] For a \tb{State machine} from the Moka example set, we use our code generation tool to generate code.
	
	
	\item[Step 2] We simulate the execution of the \tb{State machine} by using Moka to extract a sequence \tb{Trace 1} of observed traces including executed actions.
	
	\item[Step 3] The sequence (\tb{Traces 2}) is obtained through the runtime execution of the code generated in Step 1.
	
	\item[Step 5] \ttt{Trace 1} and \ttt{Trace 2} are compared. The code is semantic-conformant if \tb{Traces 1} and \tb{Traces 2} are the same \cite{Blech2005}. 
\end{description}

%Within our scope as previously defined 30 examples of the Moka example set are tested. \ti{SimTraces} and \ti{RTTraces} for each case are the same. 
%This indicates that, within our study scope, the runtime execution of code generated by our generator can produce traces semantically equivalent to those obtained via simulation. 
The PSSM test suite consists of 66 test cases for different state macchine element types.
The results are promising: our tool passes 62/66 tests including: behavior (5/6), choice (3/3), deferred events (6/6), entering (5/5), exiting (4/5), entry(5/5), exit (3/3), event (9/9), final state (1/1), fork (2/2), join (2/2), transition (11/14), terminate (3/3), others (2/2).  
In fact, our tool fails with some tests containing transitions (1) from an \ttt{entry point} to an \ttt{exit point} or (2) from an entry point/exit point to itself. 
This is, as our observation, rarely used in practice because of the contradictory semantics of \ti{entry points} and \ti{exit points} as previously discussed. 
%Furthermore, as the UML specification says that transitions outgoing from an \ttt{entry point} of a composite state should end on one of the sub-vertexes.

The results of this evaluation are not enough to prove that our pattern and tooling support preserves the UML State Machine execution properties but are a good hint that runtime execution of generated code is semantically correct (for all but the case identified above).


This evaluation methodology has the limitation that it is dependent on PSSM.
Currently, for event support, PSSM only specifies signal events.
For pseudo-states, histories are not supported.
Thus, our evaluation result is limited to the current specification of PSSM.

\begin{figure}
	\centering
	\includegraphics[clip, trim=0.2cm 8.6cm 16.7cm 6.9cm, width=\columnwidth]{figures/semanticconformance.pdf}
	\caption{Semantic conformance evaluation methodology} 
	\label{fig:semanticconformance}
\end{figure}		

\begin{comment}
\begin{table*}[]
	\centering
	\caption{Semantic-conformance test results (number of passed/total tests)}
	\label{table:semantic-test}
	\begin{tabular}{|l|l|l|l|l|l|l|l|l|l|l|l|l|l|}
		\hline
		Behavior & Choice & Deferred Events & Entering & Exiting & Entry & Exit & Event & Final & Fork & Join & Transition & Terminate & Others \\ \hline
		5/6&        3/3&         6/6        &    5/5      &    4/5     &  5/5     &   3/3   &    9/9    &   1/1    &   2/2   &   2/2   &      11/14      &    3/3       &    2/2    \\ \hline
	\end{tabular}
\end{table*}
\end{comment}

\vskip 0.1cm
\noindent
\tb{Threats to validity:}
%All test cases of the PSSM test suite are contained in a single model file.
%However, the input to our experiments requires a test case per model file.
Operation behaviors in PSSM are defined by activities while our prototype requires fine-grained behavior as blocks of code embedded into models.
Therefore, an internal threat is that we manually re-create these tests and convert activities into programming language code.

\input{sections/benchmark}


%\lipsum[1-6]